# Повторение результатов статьи 

Повторяем эксперимент из статьи

```
Bunel, R., Hausknecht, M., Devlin, J., Singh, R., & Kohli, P. (2018). 
Leveraging grammar and reinforcement learning for neural program synthesis. 
arXiv preprint arXiv:1805.04276.
```

В статье предлагается использовать обучение с подкреплением и отсев генерируемых вариантов программ путем из их исполнения и проверки синтаксиса.

Используется сгенерированный датасет [karel_dataset](https://msr-redmond.github.io/karel-dataset/).

Исходный код для начала эксперимента доступен на [Github](https://github.com/bunelr/GandRL_for_NPS).

## Шпаргалка

См. подсказки по [сложным действиям](./FAQ.md)

## Как сдавать

 - [ ] решить задания по задачам, ответы на вопросы привести в этом файле или добавить в нужном пункте ссылку на ответ
 - [ ] оформить в виде git репозитория, в котором размещены все результаты
 - [ ] прислать ссылку на репозиторий письмом
 
Пример оформления ответа

 - как оформить ответ на вопрос?
> Например вот так
 - как добавить ответ ссылкой
> вот [ссылка](./TASK.md#как-сдавать)


Для обучения моделей можно использовать Google Colab c GPU.

## Задача 1. Подготовка данных

### Задание 1. 

Получите karel_dataset, найдите в нем train.json и разберитесь в его структуре.


Вопросы
 - как правильно называется формат файла train.json?
 > TDB
 - как взять часть из файла train.json?
 > Поскольку каждая строка - корректный JSON, удобно пользоваться командой `head`
 - подготовьте файлы корректного формата размером 1%, 3%, 10% от оригинала train.json
```
andresokol@andresokol-vla:~/jup/1m_6ex_karel$ wc -l train.json 
1116854 train.json
andresokol@andresokol-vla:~/jup/1m_6ex_karel$ head -n 11168 train.json > train_1p.json
andresokol@andresokol-vla:~/jup/1m_6ex_karel$ head -n 33505 train.json > train_3p.json
andresokol@andresokol-vla:~/jup/1m_6ex_karel$ head -n 111685 train.json > train_10p.json
```

### Задание 2. 
 
Напишите код, который загружает данные из train.json
 
Вопросы
 - оцените объем необходимой RAM
 - реализуйте загрузку в итератор словарей (паттерн итератор)
  
## Задача 2. Подготовка репозитория 

### Задание 1. 

Получите GandRL_for_NPS из github и смерджите его в этот репозиторий (см. [как это сделать](./FAQ.md#как-объединить-репозитории) в FAQ.md)

Вопросы
 - на каком языке реализован?
 > python 2.7
 - что нужно сделать для установки эксперимента и зависимостей?
 > установить библиотеку pytorch, установить cython, выполнить setup.py
 - где должны быть размещены данные?
 > где угодно, путь к данным передается параметром
 - что нужно сделать для запуска эксперимента, как указать параметры и какие значения выбрать?
 > Запускал на предложенных авторами параметрах, подправив размер батча под мою видеокарту. Пример команды:
 ```
 python train_cmd.py --kernel_size 3 `
             --conv_stack "64,64,64" `
             --fc_stack "512" `
             --tgt_embedding_size 256 `
             --lstm_hidden_size 256 `
             --nb_lstm_layers 2 `
             --signal supervised `
             --nb_ios 5 `
             --nb_epochs 10 `
             --optim_alg Adam `
             --batch_size 128 `
             --learning_rate 1e-4 `
             --train_file C:\Users\andresokol-win\Documents\code\miptap\gandrl_nps\data/1m_6ex_karel/train_1p.json `
             --val_file C:\Users\andresokol-win\Documents\code\miptap\gandrl_nps\data/1m_6ex_karel/val.json `
             --vocab C:\Users\andresokol-win\Documents\code\miptap\gandrl_nps\data/1m_6ex_karel/new_vocab.vocab `
             --result_folder exps/supervised_use_grammar `
             --use_grammar `
             --use_cuda
```
 - что нужно сделать для проверки обученной модели?
 > запустить команду для проверки, пример:
```

python eval_cmd.py --model_weights exps/supervised_use_grammar/Weights/weights_1.model `
            `
            --vocabulary C:\Users\andresokol-win\Documents\code\miptap\gandrl_nps\data/1m_6ex_karel/new_vocab.vocab `
            --dataset C:\Users\andresokol-win\Documents\code\miptap\gandrl_nps\data/1m_6ex_karel/val.json `
            --eval_nb_ios 5 `
            --eval_batch_size 8 `
            --output_path exps/supervised_use_grammar/Results/ValidationSet_ `
            --beam_size 64 `
            --top_k 10 `
            --dump_programs `
            --use_grammar `
            --use_cuda
```
 
### Задание 2. 
 
Загрузите 1% от train.json и остальные файлы из karel_dataset
 
Вопросы
 - зачем нужны файлы *.thdump в папке датасета?
 > в thdump лежат подготовленные токенизированные данные, преобразованные из сырого текста 
 - что содержит new_vocab?
 > 
 - где находится датасет для контроля и для теста?
 > в файлах val.json и test.json
 - как устроен экземпляр данных для обучения?

### Задание 3. 

Проведите эксперимент с 1% данных

Вопросы
 - как указать вид модели?
 > вид модели задается аргументом к команде
 - какие ошибки возникли при запуске и как вы их устранили?
 > возникли ошибки, связанные с изменениями апи библиотек и разницей Python 2 -> 3
 - сколько эпох вы провели?
 > 10
 - где сохранены результаты и логи эксперимента?
 > путь задается параметром --result_folder 
 - какого качества получен результат?
 
3а. Оператор m += 1 имеет другое значение, чем m = m + 1. Также воспользуйтесь явным приведением типов
 
3б. Из-за разных версий torch может потребоваться адаптировать код проекта. Например, для получения значения из тензора размером 1 нужно вызывать ``item()`` вместо ``[0]``

3в. Удалите кэши данных перед запуском

3г. Попробуйте заменить tqdm на progressbar2, см. [вот это сообщение](https://github.com/tqdm/tqdm/issues/613) или установить версию 2018 года.

3д. После обновления кода не забывайте установить повторно через setup.py

 
### Задание 4. 
 
Сделайте свой клон репозитория с исправлениями, добавьте архивы подготовленных данных 1%, 3%, 10% на файлообменник с доступом по прямой ссылке
 
Вопросы
 - как получить данные по ссылке из командной строки?
 - где находится ваш репозиторий?

### Задание 5*.

Подключите журналирование кривых обучения и промежуточных результатов в [TensorboardX](https://github.com/lanpa/tensorboardX). 
Для этого нужно использовать SummaryWriter для сохранения промежуточных значений функции потерь внутри цикла обучения. Например, после каждого минибатча или 100 миниматчей. 

Логи сохранять в подпапку ``runs`` папки эксперимента в ``./exps/*``

Для использования установить Tensorboard и указать данную папку в качестве исходной.
  
## Задача 3. Анализ и повторение результата

### Задание 1. 

Проведите эксперименты для 1%, 3%, 10% данных для MLE (supervised), RL_beam и обучаемой и предзаданной моделью синтаксиса

Вопросы
 - сколько времени заняло проведение эксперимента, какие ресурсы использовали?
 - какого качества удалось достичь?
 - приведите 10 примеров синтеза программы для karel обученной моделью

Начните с MLE и используйте обученную таким образом модель для RL в качестве начального приближения.
См. подробнее в репозитории проекта.

### Задание 2. 

Подготовьте слайды по эксперименту: 
1. название статьи и постановка задачи (по статье, формулы) 
2. использованные данные (ссылка и как готовили)
3. постановка эксперимента (репо и команды запуска)
4. таблица с результатами (сводная)

Вопросы
 - сравните с результатами для Small dataset из статьи, удалось ли повторить их результаты?
 - как влияет выбор алгоритма контроля корректности программы на качество, в зависимости от размера?


